import rasterio
import geopandas as gpd
from rasterio.windows import Window
from shapely.geometry import box

# Path to the raster file
raster_file = "path_to_your_raster_file.tif"

# Initialize an empty GeoDataFrame to store the results
gdf_list = []

# Specify the desired window size
window_size = 512  # Adjust this value according to your memory constraints

# Read the raster file
with rasterio.open(raster_file) as src:
    # Iterate over the raster dataset with fixed window size
    for col_off in range(0, src.width, window_size):
        for row_off in range(0, src.height, window_size):
            # Define the window
            window = Window(col_off, row_off, window_size, window_size)
            
            # Read data for the current window
            data = src.read(1, window=window)
            
            # Calculate the bounding box coordinates of the window
            transform = src.window_transform(window)
            xmin = transform.c + col_off * transform.a
            ymax = transform.f + row_off * transform.e
            xmax = xmin + window_size * transform.a
            ymin = ymax - window_size * transform.e
            
            # Create a bounding box geometry
            bbox = box(xmin, ymin, xmax, ymax)
            
            # Create a GeoDataFrame for the current window
            gdf = gpd.GeoDataFrame({'value': data.flatten()}, geometry=[bbox])
            
            # Append the GeoDataFrame to the list
            gdf_list.append(gdf)

# Concatenate all GeoDataFrames into a single GeoDataFrame
final_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))

# Plot the final GeoDataFrame
final_gdf.plot(column='value', cmap='viridis', legend=True)



def extract_raster_file(dataset_path, raster_filename):
    # Construct the full path to the raster file within the dataset
    full_path = os.path.join(dataset_path, raster_filename)

    # Check if the raster file exists
    if not os.path.isfile(full_path):
        raise FileNotFoundError(f"Raster file '{raster_filename}' not found in the dataset.")

    # Open the raster file using rasterio
    with rasterio.open(full_path) as src:
        # Read the raster data
        raster_data = src.read(1)  # Assuming you want to read the first band

        # Create a temporary file to save the raster data
        tmp = tempfile.NamedTemporaryFile(suffix='.tif', delete=False)
        with rasterio.open(tmp.name, 'w', driver='GTiff', width=src.width, height=src.height, count=1,
                           dtype=raster_data.dtype, crs=src.crs, transform=src.transform) as dst:
            dst.write(raster_data, 1)  # Write the raster data to the temporary file

        return tmp.name
    def extract_raster_file(ds, glob_filename):
        fs = ds.filesystem()

        files = list(fs.ls(glob=glob_filename))
        print(files)
        fname = files[0][0]
        print(fname)

        tmp = tempfile.NamedTemporaryFile()
        with fs.open(fname, "rb") as f:
            shutil.copyfileobj(f, tmp)
            tmp.flush()

        return tmp
#  rasterfile_raw = u.extract_raster_file(ds_raw, rastername)

    raster_file_veg = extract_raster_file(dead_tree_img, 'Dead_tree_canopy_cover_3m/California-Vegetation-DeadTreeCover-2018-fall-00003m.tif'
        )










def start():
    transforms = []
    raster_files = constants.RASTER_FILES

    for raster_file in raster_files:
        raster_file_output = constants.RASTER_OUTPUT_BASE_PATH.format(f"{raster_file}")
        raster_file_path = f"production/spatial_data/{raster_file}.tif.parquet"
        transforms = add_geometry_parquet_transforms(transforms, constants.RASTER_INPUT_SOURCE, raster_file_output, raster_file_path)
    
    return transforms


def add_geometry_parquet_transforms(transforms, fs_dataset, output_path, submodel_prediction_file_path):
    @configure_geospatial()
    @transform(
        out_dataset=Output(output_path),
        input_dataset=Input(fs_dataset)
    ) 
    def convert_to_dataset(input_dataset, out_dataset, ctx):
        fs = input_dataset.filesystem()
        hadoop_path = fs.hadoop_path
        file_list = list(fs.ls())
        paths = [hadoop_path + '/' + f.path for f in file_list]
        for i in paths:
            if submodel_prediction_file_path in i:
               fileT = [i, ]
               df = ctx.spark_session.read.parquet(*fileT)
               SedonaRegistrator.registerAll(ctx.spark_session)
               df = df.withColumn('geometry', ST.geom_from_wkt('geometry_wkt'))
               df = df.withColumn('geometry', ST.as_geo_json('geometry'))                
               out_dataset.write_dataframe(df)

    transforms.append(convert_to_dataset)
    return transforms

