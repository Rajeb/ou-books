
# Calculate monthly averages
monthly_avg = df.groupBy("year", "month").agg(
    avg("smois_0_avg").alias("avg_smois_0"),
    avg("rh2m_avg").alias("avg_rh2m"),
    avg("temp_f_50m_avg").alias("avg_temp_f_50m"),
    avg("vpd_mb_50m_avg").alias("avg_vpd_mb_50m"),
    avg("ws_mph_50m_avg").alias("avg_ws_mph_50m"),
    avg("ndvi_avg").alias("avg_ndvi")
)

# Define seasons
df_with_season = df.withColumn(
    "season",
    when((col("month").isin(3, 4, 5)), "Spring")
    .when((col("month").isin(6, 7, 8)), "Summer")
    .when((col("month").isin(9, 10, 11)), "Fall")
    .otherwise("Winter")
)


def standardize (df, columns):
    df_standardized = df.copy()
    for col in columns:
        mean = df[col].mean()
        std = df[col].std()
        df_standardized[col]=(df[col]-mean)/std
    return df_standardized

monthly_agg_std.rename(columns=lambda x: x.replace('_avg', '_stand') if x in col_to_standardize else x, inplace=True)

# Step 2: Standardize the Monthly and Seasonal Averages
def standardize(df, columns):
    df_standardized = df.copy()
    for col in columns:
        mean = df[col].mean()
        std = df[col].std()
        df_standardized[col] = (df[col] - mean) / std
    return df_standardized

# Identify columns to standardize
columns_to_standardize = [col for col in monthly_agg.columns if col.endswith('_avg')]

# Standardize the monthly and seasonal average DataFrames
monthly_agg_std = standardize(monthly_agg, columns_to_standardize)
seasonal_agg_std = standardize(seasonal_agg, columns_to_standardize)

# Rename columns to indicate they are standardized
monthly_agg_std.rename(columns=lambda x: x.replace('_avg', '_stand') if x in columns_to_standardize else x, inplace=True)
seasonal_agg_std.rename(columns=lambda x: x.replace('_avg', '_stand') if x in columns_to_standardize else x, inplace=True)

Extreme Events:

Outliers: Extreme values can skew average calculations, especially in non-normally distributed data. Techniques like trimming or winsorizing can help mitigate this.
Event Frequency: The distribution affects how extreme events are represented when aggregated. For example, using gamma distribution for precipitation can better capture the frequency of heavy rainfall days compared to a normal distribution.
Seasonality and Trends:

Recognizing the underlying distribution helps in identifying and adjusting for seasonal patterns and trends. For instance, temperature might follow a sinusoidal pattern annually, while precipitation could be more sporadic.

pomms2km_we_sn	day	month	year	smois_0_avg	smois_0_stddev	rh2m_avg	rh2m_stddev	temp_f_50m_avg	temp_f_50m_stddev	vpd_mb_50m_avg	vpd_mb_50m_stddev	ws_mph_50m_avg	ws_mph_50m_stddev	ndvi_avg	smois_0_50perc	rh2m_50perc	temp_f_50m_50perc	vpd_mb_50m_50perc	ws_mph_50m_50perc	ndvi_50perc
0	100_270	1	1	2023	1.000000	0.000000	74.104179	4.168379	49.457165	1.959504	3.562420	0.849011	15.894864	4.656382	0.722732	1.000000	75.166824	49.081264	3.422746	15.333195	0.722732
1	100_274	1	1	2023	0.325845	0.002962	75.223183	18.427027	46.644653	3.994380	3.879106	2.435778	15.641371	6.138577	0.546710	0.324978	81.647766	46.371780	3.586078	15.016594	0.546710
2	100_279	1	1	2023	0.323945	0.004028	68.933502	17.915028	47.635063	4.198934	4.552250	2.639466	15.712668	7.388672	0.555000	0.322582	65.179375	47.511330	4.836389	15.338800	0.555000
3	100_280	1	1	2023	0.327399	0.003464	71.235413	18.303837	46.255745	4.340581	4.149383	2.682920	15.914797	6.469522	0.553595	0.326535	69.994827	46.405048	4.204945	13.767526	0.553595
4	100_283	1	1	2023	0.331599	0.003620	74.798073	20.798466	46.916233	4.346962	4.084214	2.603724	9.907588	3.001863	0.583332	0.330459	73.641136	46.739376	4.295482	10.083474	0.583332
5	100_284	1	1	2023	0.331902	0.003602	72.524490	18.697302	46.061348	4.201504	4.004932	2.574498	14.251508	4.239246	0.550814	0.330701	68.129959	45.610176	3.647069	13.773910	0.550814
6	100_294	1	1	2023	0.328661	0.003862	86.942406	15.446038	42.820847	3.908178	1.723404	1.892801	8.286879	3.439797	0.551593	0.327870	93.613655	42.138550	1.011464	8.064075	0.551593
7	100_295	1	1	2023	0.327710	0.003825	86.902565	16.585463	43.309406	4.183506	1.805126	2.042001	6.638252	2.984449	0.545304	0.326826	95.928864	41.721485	0.982995	6.580966	0.545304
8	100_299	1	1	2023	0.329020	0.003711	78.735832	21.218067	43.372383	4.310484	3.207421	2.347995	10.108923	3.991436	0.530887	0.328142	74.175400	42.002769	2.602644	9.099835	0.530887
9	100_302	1	1	2023	0.331842	0.003700	76.409210	21.577551	41.702618	4.083037	3.253897	2.285851	12.886290	4.369962	0.539838	0.330742	73.086601	41.029907	2.811944	12.433921	0.539838
AttributeError: `np.deprecate` was removed in the NumPy 2.0 release. Emit `DeprecationWarning` with `warnings.warn` directly, or use `typing.deprecated`.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
pymc3 3.11.6 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.22.2 which is incompatible.
statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.2 which is incompatible.
statsmodels 0.14.2 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.







WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.

############# Plotting


import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.dates import DateFormatter, MonthLocator

# Sample data creation (You can replace this with your actual DataFrame)
np.random.seed(0)
dates = pd.date_range(start='2015-01-01', end='2024-07-15', freq='D')
data = {
    'date': np.random.choice(dates, 1000),
    'outage_record': np.random.randint(1, 100, 1000),
    'ignition_record': np.random.randint(1, 100, 1000),
    'cause': np.random.choice(['bird', 'other'], 1000),
    'temperature': np.random.uniform(10, 35, 1000)
}
df = pd.DataFrame(data)

# Filter the DataFrame for the selected years and where cause is 'bird'
selected_years = [2015, 2022, 2023]
df['date'] = pd.to_datetime(df['date'])
df['year'] = df['date'].dt.year
df['day_of_year'] = df['date'].dt.dayofyear
bird_data = df[(df['year'].isin(selected_years)) & (df['cause'] == 'bird')]

# Group by 'year' and 'day_of_year', then count the occurrences
daily_counts = bird_data.groupby(['year', 'day_of_year']).size().reset_index(name='count')
daily_counts['cumulative_count'] = daily_counts.groupby('year')['count'].cumsum()

# Calculate daily average temperature for each day of the year
avg_temp = df.groupby('day_of_year')['temperature'].mean().reset_index()

# Create a new column for the date corresponding to the day of the year in a non-leap year
daily_counts['date'] = pd.to_datetime(daily_counts['day_of_year'], format='%j', errors='coerce')
avg_temp['date'] = pd.to_datetime(avg_temp['day_of_year'], format='%j', errors='coerce')

# Plot the cumulative counts
fig, ax1 = plt.subplots(figsize=(14, 10))

for year, group in daily_counts.groupby('year'):
    ax1.plot(group['date'], group['cumulative_count'], label=year)

# Customize the primary x-axis and y-axis
ax1.set_xlabel('Day of Year', fontsize=14)
ax1.set_ylabel('Cumulative Count', fontsize=14)
ax1.set_title('Cumulative Bird Strikes per Selected Year by Day and Daily Average Temperature', fontsize=20)
ax1.legend(title='Year', fontsize=10, title_fontsize='12')
ax1.grid(True)

# Create a secondary y-axis for daily average temperature
ax2 = ax1.twinx()
ax2.plot(avg_temp['date'], avg_temp['temperature'], label='Avg Temp', color='red', linewidth=2, linestyle='dashed')
ax2.set_ylabel('Daily Average Temperature (Â°C)', fontsize=14)

# Create a secondary x-axis
ax3 = ax1.secondary_xaxis('top', functions=(lambda x: x, lambda x: x))
ax3.xaxis.set_major_locator(MonthLocator())
ax3.xaxis.set_major_formatter(DateFormatter('%b'))
ax3.set_xlabel('Month', fontsize=14)

plt.tight_layout()
plt.show()









