Qian, C., Yao, C., Ma, H., Xu, J., & Wang, J. (2023). Tree species classification using airborne lidar data based on individual tree segmentation and shape fitting. Remote Sensing, 15(2), 406.
Chen, C., Jing, L., Li, H., Tang, Y., & Chen, F. (2023). Individual Tree Species Identification Based on a Combination of Deep Learning and Traditional Features. Remote Sensing, 15(9), 2301.


Searched 3 sites
Research on tree species identification at the species level has made significant progress using LiDAR, multispectral, and hyperspectral imagery. However, there are several notable research gaps:

Data Fusion Challenges: Integrating multiple sensor types like LiDAR and hyperspectral imagery requires advanced methods to harmonize different data formats and resolutions. The variability in spatial, temporal, and spectral characteristics complicates effective fusion, limiting species-level classification accuracy (MDPI, 2023).

Within-Species Variability: High variability in leaf reflectance, crown shapes, and growth forms within the same species presents a challenge for machine learning models. More research is needed to address how these variations affect classification accuracy, especially in complex forest environments (MDPI, 2023).

Limited Generalizability Across Regions: Models trained in one geographical area often struggle to generalize to others due to differences in species composition, canopy structures, and environmental conditions. Developing universally applicable models remains a challenge (MDPI, 2023).

Automation and Efficiency: Manual segmentation of individual trees from remote sensing data is labor-intensive. Although automated approaches using machine learning are emerging, achieving high accuracy consistently across diverse forest types is still difficult (Remote Sens., 2023).

Dimensionality Reduction and Feature Selection: While hyperspectral data provide rich information, they also introduce high dimensionality. Identifying the most relevant features for tree species classification while reducing computational complexity remains a significant gap (MDPI, 2023).

Future research should focus on refining data fusion techniques, enhancing model robustness across various environments, and improving automation in species classification workflows to address these gaps.


8 band description
----------------------------
Our deep learning model uses satellite imagery from PlanetScope to detect canopy survival and mortality. PlanetScope by Planet Labs is a commercial constellation of 180+ CubeSat satellites collecting near- daily 4-band (RGB/NIR) imagery at 3-m spatial resolution. PlanetScope
was chosen as the set of predictors because it often contains suffi- cient spatial resolution to observe individual forest canopies and its higher temporal frequency enables the exploitation of pre- and post- disturbance observations as well as intra-annual canopy variability.
Within each fire of interest, we downloaded all PlanetScope imagery from May 1 to October 31 with <70% cloud cover, having a solar elevation ≥ 10◦, and meet ‘‘standard’’ quality according to Planet’s metadata (Roy et al., 2021). Images were masked using the Usable Data Mask 2 provided by Planet to select ‘‘clear sky’’ pixels. Because of
4
D.J. Dixon et al.
Remote Sensing of Environment 298 (2023) 113842
spectral inconsistencies between image dates and sensors, we applied a harmonization function provided by Planet to approximately match the Sentinel-2 spectral response for each image. Monthly median com- posites from May to October were calculated for a pre-fire year and a post-fire year defined by the year of the fire and the timing of each NAIP acquisition. This use of median composites minimizes the potential layover effects between PlanetScope images or undetected noise within single images. Pre-fire PlanetScope imagery were gathered for the first year before the fire year, and post-fire imagery for the first (3/15 fires) or second (12/15) year after the fire to temporally align with NAIP manual canopy labeling (S1 Table). Although rare, there were cases of zero clear sky pixels occurring over the course of an entire month; this occurred with 0.035% of pixels across all training, validation and test quadrants. For those cases, we used the subsequent or closest monthly composite for gap filling, and the final product includes a quality flag to note those cases. S2 and S3 Figures show density plots of image date counts, cases of zero image gaps, and the timing of image acquisitions used for each month and ecoregion.
----
paraphrase
Our deep learning model uses PlanetScope satellite imagery (4-band RGB/NIR, 3-m resolution) to detect forest canopy survival and mortality. PlanetScope's high spatial resolution and near-daily temporal frequency allow for observing individual canopies and capturing pre- and post-disturbance variability. For each fire event, we downloaded imagery from May to October with <70% cloud cover, solar elevation ≥10°, and "standard" quality per Planet's metadata.

Imagery was pre-processed using Planet's Usable Data Mask 2 for clear sky pixels and a harmonization function to align spectral responses with Sentinel-2. Monthly median composites were created for pre- and post-fire years, reducing noise and temporal mismatches. Gaps due to missing clear sky pixels (<0.04% of cases) were filled with the nearest monthly composite, flagged for quality. This dataset supports robust canopy change detection, aligning with NAIP manual labeling.



match with ground data
---------------------------
After segmenting the full study area, we matched the delineated tree crowns and our field measurements with the following algorithm: For each tree crown segment, we checked whether it contained any field data measurements. If there was only one field data point within a tree crown, then the tree crown was labeled with this field data point. If two or more measured trees were located inside one tree crown segment, then we used the following rules: If any of these field data points was individually measured, we only considered individually measured trees within the segmented crown as a valid label for the corresponding tree crown due to their higher spatial accuracy. Finally, the tree crown was labeled with the close






Data Scale: Many studies have focused on small-scale datasets or individual sites, limiting the generalizability of models to broader landscapes. Although some models achieve high accuracy in controlled environments, they often fail when applied to larger, more heterogeneous regions due to variations in species composition, canopy structure, and environmental factors (MDPI, 2023). Expanding datasets to cover large, diverse geographical areas is essential for improving model robustness.

Data Coverage: Current research often suffers from limited coverage, focusing on specific tree species or forest types. This narrow focus may not adequately address the wide variety of tree species present in different ecosystems (Remote Sens., 2023). To create universal models for tree species classification, more comprehensive datasets that include a broad range of species, from temperate to tropical forests, are needed.

Data Diversity: Studies commonly use specific types of remote sensing data (e.g., LiDAR, multispectral imagery), but the lack of diversity in data sources can impact model performance. For example, hyperspectral imagery, while rich in spectral information, is often underutilized in large-scale studies due to its high dimensionality and complexity (MDPI, 2023). Additionally, incorporating temporal data and considering seasonal changes in vegetation reflectance could further enhance the accuracy and reliability of classification models.

In conclusion, addressing these gaps—expanding the scale of data, broadening species coverage, and diversifying the types of data used—will significantly enhance the applicability and precision of tree species identification for wildfire mitigation and forest management.








Data Integration and Fusion: While multimodal models, which integrate data from different sensors (e.g., LiDAR, multispectral, hyperspectral), have shown promise, integrating these diverse data sources efficiently remains a challenge. Differences in data resolution, scale, and dimensionality can cause issues when attempting to fuse them for species-level classification. Effective fusion strategies that can handle this variability are still underdeveloped, limiting the full potential of multimodal deep learning models (MDPI, 2023; Remote Sens., 2023).

Model Generalization and Overfitting: A key challenge is the generalization of deep learning models trained on specific datasets to new, unseen regions or species. Multimodal architectures tend to overfit when trained on small, region-specific datasets, reducing their effectiveness in large-scale, diverse environments. Research is needed to develop robust models that can perform consistently across different geographical areas with varying species compositions (Remote Sens., 2023).

Temporal Dynamics: Another gap is the integration of temporal data into multimodal architectures. While many studies focus on static images or point clouds, the ability to incorporate temporal changes in tree structures or environmental conditions into models remains underexplored. Leveraging time-series data, such as seasonal changes in vegetation reflectance, could improve the accuracy and adaptability of species identification models (MDPI, 2023).

Model Efficiency and Scalability: Deep learning models, especially multimodal architectures, are often computationally expensive, which limits their scalability to large datasets. There is a need for more efficient algorithms and architectures that can process large-scale remote sensing data in real time or near real-time without compromising accuracy (Remote Sens., 2023).

In conclusion, addressing these gaps—focusing on better data integration, improving model generalization, incorporating temporal information, and enhancing model efficiency—will be essential to advancing multimodal deep learning techniques for tree species identification, particularly in large-scale forest management and wildfire mitigation applications.





In this study, we present an approach for national tree species mapping based on S1/S2 time series and national forest inventory data to provide a foundation for future consistent European-wide species mapping efforts. We test our approach for the area of Germany using field data from variable-radius plots of the German National Forest Inventory (NFI). Specifically, we address the following research questions:  1. Which accuracies can be achieved on a national scale when combining NFI observations with S1 and S2 time series data and environmental conditions for mapping major tree species groups? 2. How different are the classification accuracies between homogenous pure-species and mixed-species forest stands? 3. How do the mapped species areas compare to NFI-based area estimates?


objectives"

In this study, we propose an approach for tree species mapping within the PG&E service territory using terrestrial LiDAR data and 8-band reflectance data. This mapping effort aims to provide a solid foundation for wildfire risk mitigation programs. Specifically, we address the following research questions:

How accurate can deep learning architectures based on LiDAR data achieve when combined with tree inventory data collected at ground level for mapping tree species within the service territory?
How do classification accuracies compare between models using only LiDAR data, multispectral reflectance data, and a combination of both when evaluated against ground truth data?
Are there certain tree species that perform better in classification than others, and do specific approaches (LiDAR-based, reflectance-based, or combined) yield superior results for certain species?
This approach will contribute to refining wildfire risk management strategies by enhancing the accuracy of tree species identification and improving vegetation risk assessmen
