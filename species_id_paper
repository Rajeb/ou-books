_________
The ability of transformers to model long-range dependencies and efficiently integrate multiple modalities has facilitated breakthroughs in vision-language tasks and beyond. Notably, models like Flamingo (Alayrac et al., 2022) have demonstrated superior performance by jointly encoding visual and textual information. This success has motivated broader integration of modalities, including LiDAR and spectral data, fostering advancements in tasks such as remote sensing and environmental monitoring
_________

Transformers' capacity to capture long-range dependencies and integrate multiple modalities has driven significant progress in vision-language tasks and beyond. Models like Flamingo (Alayrac et al., 2022) excel by jointly encoding visual and textual data, inspiring the broader fusion of modalities such as LiDAR and spectral information, advancing applications in remote sensing and environmental monitoring

--------------------
Mapping tree species is essential for wildfire mitigation, biodiversity conservation, forest resilience, and sustainable forest management under the changing climate. Despite advancements in tree species classification driven by emerging remote sensing technologies and deep learning methods, several challenges persist in the utilization of data sources and the application of deep learning techniques. Low-resolution satellite data lack the spatial detail to resolve species in heterogeneous landscapes, and many studies are limited by scarce, high-quality ground truth data and small study areas with few species, limiting scalability and generalization to diverse ecosystems.


Qian, C., Yao, C., Ma, H., Xu, J., & Wang, J. (2023). Tree species classification using airborne lidar data based on individual tree segmentation and shape fitting. Remote Sensing, 15(2), 406.
Chen, C., Jing, L., Li, H., Tang, Y., & Chen, F. (2023). Individual Tree Species Identification Based on a Combination of Deep Learning and Traditional Features. Remote Sensing, 15(9), 2301.

___________
explain confusion matrix for Multi modal
The sensitivity results for the model demonstrate significant variation across the 20 species, with marked discrepancies in classification performance (Table X). Monterey pines exhibited the highest sensitivity at 93%, representing a strong true positive rate for this species. In contrast, species such as Jeffery/Ponderosa pines (10%), stone fruit oaks (6%), and the "other" category (7%) had notably low sensitivity, indicating a high rate of false negatives. Species like true redwoods (78%), eucalyptus trees (72%), and gray pines (52%) exhibited moderate sensitivity, suggesting a reasonable balance between true positives and false positives. The model’s mean sensitivity of 32.7% across all classes reflects a low overall performance, with high variability (heterogeneity) in the classification accuracy among different species.
-----------------------
The model demonstrated high overall sensitivity (92.7%) but with considerable variability across species. Monterey pines exhibited the highest sensitivity (93%), whereas Jeffery/Ponderosa pines (10%), stone fruit oaks (6%), and the "other" category (7%) had high false negative rates, likely due to limited LiDAR feature distinctiveness or class imbalance. True redwoods (78%), eucalyptus (82%), and gray pines (62%) showed moderate sensitivity. Despite these disparities, MM achieved the highest overall classification performance.

Searched 3 sites
Research on tree species identification at the species level has made significant progress using LiDAR, multispectral, and hyperspectral imagery. However, there are several notable research gaps:

Data Fusion Challenges: Integrating multiple sensor types like LiDAR and hyperspectral imagery requires advanced methods to harmonize different data formats and resolutions. The variability in spatial, temporal, and spectral characteristics complicates effective fusion, limiting species-level classification accuracy (MDPI, 2023).

Within-Species Variability: High variability in leaf reflectance, crown shapes, and growth forms within the same species presents a challenge for machine learning models. More research is needed to address how these variations affect classification accuracy, especially in complex forest environments (MDPI, 2023).

Limited Generalizability Across Regions: Models trained in one geographical area often struggle to generalize to others due to differences in species composition, canopy structures, and environmental conditions. Developing universally applicable models remains a challenge (MDPI, 2023).

Automation and Efficiency: Manual segmentation of individual trees from remote sensing data is labor-intensive. Although automated approaches using machine learning are emerging, achieving high accuracy consistently across diverse forest types is still difficult (Remote Sens., 2023).

Dimensionality Reduction and Feature Selection: While hyperspectral data provide rich information, they also introduce high dimensionality. Identifying the most relevant features for tree species classification while reducing computational complexity remains a significant gap (MDPI, 2023).

Future research should focus on refining data fusion techniques, enhancing model robustness across various environments, and improving automation in species classification workflows to address these gaps.


8 band description
----------------------------
Our deep learning model uses satellite imagery from PlanetScope to detect canopy survival and mortality. PlanetScope by Planet Labs is a commercial constellation of 180+ CubeSat satellites collecting near- daily 4-band (RGB/NIR) imagery at 3-m spatial resolution. PlanetScope
was chosen as the set of predictors because it often contains suffi- cient spatial resolution to observe individual forest canopies and its higher temporal frequency enables the exploitation of pre- and post- disturbance observations as well as intra-annual canopy variability.
Within each fire of interest, we downloaded all PlanetScope imagery from May 1 to October 31 with <70% cloud cover, having a solar elevation ≥ 10◦, and meet ‘‘standard’’ quality according to Planet’s metadata (Roy et al., 2021). Images were masked using the Usable Data Mask 2 provided by Planet to select ‘‘clear sky’’ pixels. Because of
4
D.J. Dixon et al.
Remote Sensing of Environment 298 (2023) 113842
spectral inconsistencies between image dates and sensors, we applied a harmonization function provided by Planet to approximately match the Sentinel-2 spectral response for each image. Monthly median com- posites from May to October were calculated for a pre-fire year and a post-fire year defined by the year of the fire and the timing of each NAIP acquisition. This use of median composites minimizes the potential layover effects between PlanetScope images or undetected noise within single images. Pre-fire PlanetScope imagery were gathered for the first year before the fire year, and post-fire imagery for the first (3/15 fires) or second (12/15) year after the fire to temporally align with NAIP manual canopy labeling (S1 Table). Although rare, there were cases of zero clear sky pixels occurring over the course of an entire month; this occurred with 0.035% of pixels across all training, validation and test quadrants. For those cases, we used the subsequent or closest monthly composite for gap filling, and the final product includes a quality flag to note those cases. S2 and S3 Figures show density plots of image date counts, cases of zero image gaps, and the timing of image acquisitions used for each month and ecoregion.
----
paraphrase
Our deep learning model uses PlanetScope satellite imagery (4-band RGB/NIR, 3-m resolution) to detect forest canopy survival and mortality. PlanetScope's high spatial resolution and near-daily temporal frequency allow for observing individual canopies and capturing pre- and post-disturbance variability. For each fire event, we downloaded imagery from May to October with <70% cloud cover, solar elevation ≥10°, and "standard" quality per Planet's metadata.

Imagery was pre-processed using Planet's Usable Data Mask 2 for clear sky pixels and a harmonization function to align spectral responses with Sentinel-2. Monthly median composites were created for pre- and post-fire years, reducing noise and temporal mismatches. Gaps due to missing clear sky pixels (<0.04% of cases) were filled with the nearest monthly composite, flagged for quality. This dataset supports robust canopy change detection, aligning with NAIP manual labeling.



match with ground data
---------------------------
After segmenting the full study area, we matched the delineated tree crowns and our field measurements with the following algorithm: For each tree crown segment, we checked whether it contained any field data measurements. If there was only one field data point within a tree crown, then the tree crown was labeled with this field data point. If two or more measured trees were located inside one tree crown segment, then we used the following rules: If any of these field data points was individually measured, we only considered individually measured trees within the segmented crown as a valid label for the corresponding tree crown due to their higher spatial accuracy. Finally, the tree crown was labeled with the close

paraphrase:
----------------------

After segmenting the study area, each tree crown was matched to field measurements as follows:

If a tree crown contained only one field data point, it was labeled with that point.
If multiple field data points were within a crown, individually measured trees were prioritized for labeling due to their higher spatial accuracy.
The tree crown was labeled with the closest valid field data point.




Data Scale: Many studies have focused on small-scale datasets or individual sites, limiting the generalizability of models to broader landscapes. Although some models achieve high accuracy in controlled environments, they often fail when applied to larger, more heterogeneous regions due to variations in species composition, canopy structure, and environmental factors (MDPI, 2023). Expanding datasets to cover large, diverse geographical areas is essential for improving model robustness.

Data Coverage: Current research often suffers from limited coverage, focusing on specific tree species or forest types. This narrow focus may not adequately address the wide variety of tree species present in different ecosystems (Remote Sens., 2023). To create universal models for tree species classification, more comprehensive datasets that include a broad range of species, from temperate to tropical forests, are needed.

Data Diversity: Studies commonly use specific types of remote sensing data (e.g., LiDAR, multispectral imagery), but the lack of diversity in data sources can impact model performance. For example, hyperspectral imagery, while rich in spectral information, is often underutilized in large-scale studies due to its high dimensionality and complexity (MDPI, 2023). Additionally, incorporating temporal data and considering seasonal changes in vegetation reflectance could further enhance the accuracy and reliability of classification models.

In conclusion, addressing these gaps—expanding the scale of data, broadening species coverage, and diversifying the types of data used—will significantly enhance the applicability and precision of tree species identification for wildfire mitigation and forest management.








Data Integration and Fusion: While multimodal models, which integrate data from different sensors (e.g., LiDAR, multispectral, hyperspectral), have shown promise, integrating these diverse data sources efficiently remains a challenge. Differences in data resolution, scale, and dimensionality can cause issues when attempting to fuse them for species-level classification. Effective fusion strategies that can handle this variability are still underdeveloped, limiting the full potential of multimodal deep learning models (MDPI, 2023; Remote Sens., 2023).

Model Generalization and Overfitting: A key challenge is the generalization of deep learning models trained on specific datasets to new, unseen regions or species. Multimodal architectures tend to overfit when trained on small, region-specific datasets, reducing their effectiveness in large-scale, diverse environments. Research is needed to develop robust models that can perform consistently across different geographical areas with varying species compositions (Remote Sens., 2023).

Temporal Dynamics: Another gap is the integration of temporal data into multimodal architectures. While many studies focus on static images or point clouds, the ability to incorporate temporal changes in tree structures or environmental conditions into models remains underexplored. Leveraging time-series data, such as seasonal changes in vegetation reflectance, could improve the accuracy and adaptability of species identification models (MDPI, 2023).

Model Efficiency and Scalability: Deep learning models, especially multimodal architectures, are often computationally expensive, which limits their scalability to large datasets. There is a need for more efficient algorithms and architectures that can process large-scale remote sensing data in real time or near real-time without compromising accuracy (Remote Sens., 2023).

In conclusion, addressing these gaps—focusing on better data integration, improving model generalization, incorporating temporal information, and enhancing model efficiency—will be essential to advancing multimodal deep learning techniques for tree species identification, particularly in large-scale forest management and wildfire mitigation applications.





In this study, we present an approach for national tree species mapping based on S1/S2 time series and national forest inventory data to provide a foundation for future consistent European-wide species mapping efforts. We test our approach for the area of Germany using field data from variable-radius plots of the German National Forest Inventory (NFI). Specifically, we address the following research questions:  1. Which accuracies can be achieved on a national scale when combining NFI observations with S1 and S2 time series data and environmental conditions for mapping major tree species groups? 2. How different are the classification accuracies between homogenous pure-species and mixed-species forest stands? 3. How do the mapped species areas compare to NFI-based area estimates?


objectives"

In this study, we propose an approach for tree species mapping within the PG&E service territory using terrestrial LiDAR data and 8-band reflectance data. This mapping effort aims to provide a solid foundation for wildfire risk mitigation programs. Specifically, we address the following research questions:

How accurate can deep learning architectures based on LiDAR data achieve when combined with tree inventory data collected at ground level for mapping tree species within the service territory?
How do classification accuracies compare between models using only LiDAR data, multispectral reflectance data, and a combination of both when evaluated against ground truth data?
Are there certain tree species that perform better in classification than others, and do specific approaches (LiDAR-based, reflectance-based, or combined) yield superior results for certain species?
This approach will contribute to refining wildfire risk management strategies by enhancing the accuracy of tree species identification and improving vegetation risk assessmen





Results
____________________


Overall, the three models demonstrated varying levels of performance across the 20 classified species, with notable differences in their ability to handle species-specific misclassifications. 
Model 1 exhibited the highest overall accuracy but struggled with some underrepresented species, while Model 2 provided more balanced performance across species,
and Model 3 achieved moderate accuracy with a focus on minimizing false positives.


Here’s a template paragraph for comparing and contrasting model performances based on confusion matrix results for the three major tree species:

The performance of the three models was evaluated using confusion matrices, focusing on classification accuracy for the three major tree species: [Species A], [Species B], and [Species C].
For [Species A], Model 1 demonstrated the highest classification accuracy, with a notable reduction in misclassifications compared to Models 2 and 3. However, while Model 2 exhibited slightly lower accuracy for [Species A], it outperformed the other models in correctly identifying [Species B], where Model 1 struggled with higher confusion rates with [Species C]. 
Conversely, Model 3 showed balanced performance across all three species but had a slight tendency to overclassify [Species C] at the expense of [Species A]. 
These results highlight Model 1’s strength in [Species A], Model 2’s reliability for [Species B], and Model 3’s overall consistency, albeit with some trade-offs in species-specific accuracy.

Results for model 1

The MM model exhibited strong sensitivity for a few species but showed uneven performance across the 20 categories. 
Monterey pines, Jeffery/Ponderosa pines, and gray pines demonstrated the highest sensitivity, with values of 90%, 88.2%, and 84.5%, respectively.
Eucalyptus trees and true redwoods also ranked among the better-performing classes, achieving sensitivities above 79%. 
In contrast, the model faced challenges with certain species, including arbutus trees (22.4%) and the "other" category (10.9%), where sensitivity was notably low. With a mean sensitivity of 57.7% across all classes, the model performed moderately overall but revealed significant disparities, particularly for less dominant or harder-to-classify species.

Sat only model
Custom class	Sensitivity (%)
monterey_pines	93
jeffery_ponderosa_pines	10
gray_pines	52
eucalyptus trees	72
true redwoods	78
other_oaks	24
live_oaks	20
douglas firs	13
incense cedars	13
liquidambar trees	37
sugar_pines	42
black_oaks	39
umbellularia trees	35
walnuts	18
stonefruit oaks	6
fir trees	22
valley_oaks	52
poplars	9
arbutus trees	12
other	7
	
Mean across classes	32.7




The sensitivity results for the model demonstrate significant variation across the 20 species, with marked discrepancies in classification performance. 
Monterey pines exhibited the highest sensitivity at 93%, representing a strong true positive rate for this species. In contrast, species such as Jeffery/Ponderosa pines (10%), stonefruit oaks (6%), and the "other" category (7%) had notably low sensitivity, indicating a high rate of false negatives. 
Species like true redwoods (78%), eucalyptus trees (72%), and gray pines (52%) exhibited moderate sensitivity, suggesting a reasonable balance between true positives and false positives. The model’s mean sensitivity of 32.7% across all classes reflects a low overall performance, with high variability (heterogeneity) in the classification accuracy among different species. 
The results suggest a potential model bias toward certain species, as evidenced by the lower sensitivity values for less represented or more complex species.



##########
custom_class_run1	univ_specie
Abies: fir trees	White Fir, Grand Fir, Fir, True, Red Fir
Arbutus: arbutus trees	Madrone
Calocedrus: incense cedars	['Cedar']
Eucalyptus: eucalyptus trees	['Eucalyptus, Blue Gum', 'Eucalyptus, Silver Dollar Gum', 'Eucalyptus, Red-flowering Gum', 'Eucalyptus, Red Ironbark', 'Eucalyptus, Coolibah', 'Eucalyptus, Manna Gum', 'Eucalyptus', 'Eucalyptus, Red Gum']
Juglans: walnuts	['Walnut', 'Black Walnut', 'English Walnut']
Liquidambar: liquidambar trees	['Liquidambar (Sweet Gum)']
Lithocarpus: stonefruit oaks	['Tan Oak']
Pseudotsuga: douglas firs	['Douglas Fir']
Sequoia: true redwoods	['Redwood, Coast']
Umbellularia: umbellularia trees	['Bay, Calif.']
black_oaks	['Black Oak']
gray_pines	['Gray Pine']
jeffery_ponderosa_pines	['Ponderosa Pine', 'Jeffery Pine']
live_oaks	['Coast Live Oak', 'Live Oak', 'Cork Oak', 'Interior Live Oak', 'Canyon Live Oak']
monterey_pines	['Monterey Pine']
other	['Box-Elder', 'Unknown', 'Ailanthus', 'Peach', 'Bishop Pine', 'Pistache', 'Cottonwood, Black', 'Aleppo Pine', 'Hickory', 'Chinese Elm', 'Cherry', 'Plum', 'Privet', 'Acacia', 'Elm', 'Canary Island Pine', 'Dawn Redwood', 'Almond', 'Monterey Cypress', 'Italian Stone Pine', 'Apricot', 'Mulberry', 'Italian Cypress', 'Albizzia', 'Honey Locust', 'Juniper', 'Brush', 'Locust, Black', 'Mimosa', 'Silver Maple', 'Pecan', 'Buckeye', 'Birch', 'Olive', 'Blackwood Acacia', 'Pepper Tree', 'Spruce', 'Apple', 'Knobcone Pine', 'Sequoia, Giant', 'Elm, American', 'Pear']
other_oaks	['Oregon White Oak', 'Pin Oak', 'English Oak', 'Holly Oak', 'Blue Oak', 'Oracle Oak', 'Red Oak, Northern', 'Valley Oak']
poplars	['Poplar', 'Lombardy Poplar']
sugar_pines	['Sugar Pine']
valley_oaks	['Valley Oak']

The table is designed to improve clarity and readability by mapping scientific genus names (e.g., Abies, Arbutus) to relatable common names (e.g., "fir trees," "arbutus trees"), making the data accessible to both experts and lay readers. It groups related species under intuitive custom classes (e.g., Abies includes "White Fir," "Grand Fir," and "Red Fir"), emphasizing ecological, geographical, or functional similarities while maintaining scientific accuracy. Custom classes like "black oaks," "gray pines," and "live oaks" reflect practical ecological groupings, aligning with the goals of environmental studies and forestry management. The table is concise, summarizing detailed species lists into broader categories (e.g., "Eucalyptus trees") to enhance interpretability and streamline publication. Its hierarchical structure simplifies data presentation, while the "other" category ensures comprehensiveness by including less common or unidentified species. Additionally, the chosen classifications reflect the geographic and ecological relevance of the study area, such as California's significant species like "Monterey Pine" and "Valley Oak.

________________

Abstract:
Mapping tree species is essential for biodiversity conservation, forest resilience, and sustainable forest management. Despite advancements in tree species classification using satellite imagery and lidar, challenges remain. Medium-resolution satellite data lack the spatial detail to resolve species in heterogeneous landscapes, and many studies are limited by scarce, high-quality ground truth data and small study areas with few species, limiting scalability and generalization to diverse ecosystems.

This research addresses these gaps by integrating high-resolution PlanetScope imagery with lidar-derived structural data through a novel Multimodal Spatio-Temporal Convolutional Neural Network (MM-STCNN). This framework combines the spectral detail of PlanetScope and the structural insights of lidar to map tree species at fine scales (3 × 3 m). Ground truth labels were generated using lidar-based crown segmentation and expert interpretation of aerial imagery across diverse California ecoregions.

Results highlight the superiority of the multimodal approach. The satellite-only model achieved moderate accuracy (70%–80%), limited by spectral confusion in dense forests. The lidar-only model performed better in sparse landscapes, accurately distinguishing structural variations but struggled with species that share similar canopy structures. In contrast, the MM-STCNN outperformed both, with classification accuracies exceeding 90% across diverse forest types and species. The fusion of spectral and structural data enabled better differentiation, particularly among morphologically and spectrally similar species. Scalable across ecosystems, this study demonstrates the potential of multimodal data fusion to fill critical gaps in tree species mapping, advancing biodiversity monitoring and informing forest management strategies.
